{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt import risk_models, expected_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Disable all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of stock tickers\n",
    "tickers = ['AAPL', 'AMD', 'AMZN', 'CCJ', 'COST', 'GOOG', 'GS', 'JPM', 'LLY', 'META', 'MSFT', 'NEE', 'PFE', 'SAP', 'WMT']\n",
    "measurement_days = 10\n",
    "remaining_days = 30-measurement_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "AAPL\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "AMD\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "AMZN\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "CCJ\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "COST\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "GOOG\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "GS\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "JPM\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "LLY\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "META\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "MSFT\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "NEE\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "PFE\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "SAP\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "WMT\n"
     ]
    }
   ],
   "source": [
    "# Get 5 year adjusted close prices for all stocks\n",
    "\n",
    "stock_prices = {}\n",
    "short_window_prices = {}\n",
    "future_prices = {}\n",
    "\n",
    "for ticker in tickers:\n",
    "    data = yf.download(ticker,period=\"5y\")\n",
    "    print(ticker)\n",
    "    stock_prices[ticker] = data['Adj Close'].tolist()\n",
    "    stock_data = stock_prices[ticker]\n",
    "    prices_x = [stock_data[i:i+measurement_days] for i in range(len(stock_data)-remaining_days)]\n",
    "    prices_y = [stock_data[i+measurement_days] for i in range(measurement_days,len(stock_data)-measurement_days)]\n",
    "\n",
    "    prices_test = [stock_data[i:i+measurement_days] for i in range(len(stock_data)-remaining_days,len(stock_data)-measurement_days)]\n",
    "\n",
    "    short_window_prices[ticker] = (prices_x, prices_y, prices_test)\n",
    "\n",
    "    rf = RandomForestRegressor()\n",
    "    rf.fit(prices_x,prices_y)\n",
    "    # Predict stock price for 10 future days\n",
    "    future_prices[ticker] = rf.predict(prices_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         AAPL         AMD        AMZN        CCJ        COST        GOOG   \n",
      "0  177.326451  129.023400  131.336841  27.149476  530.545925  118.821504  \\\n",
      "1  175.984309  136.930700  131.703415  26.849531  534.203489  126.013539   \n",
      "2  176.729634  135.176599  129.872910  25.827114  533.955277  125.632179   \n",
      "3  176.844372  131.809300  130.689113  24.635293  536.731821  125.915529   \n",
      "4  176.693935  128.331000  131.252893  25.059906  517.334901  125.606205   \n",
      "5  176.831215  124.074900  127.158114  23.718244  528.963427  124.271205   \n",
      "6  176.698693  120.069300  124.584219  24.192806  535.073554  124.457235   \n",
      "7  176.698693  113.081301  127.025829  24.265536  539.103150  118.353554   \n",
      "8  176.698693  111.371600  133.599519  23.228341  538.678189  124.554674   \n",
      "9  176.698693  106.223600  127.327308  23.390912  542.005150  122.303634   \n",
      "\n",
      "           GS         JPM         LLY        META        MSFT        NEE   \n",
      "0  329.292164  139.587898  444.999999  277.523200  324.692267  75.595724  \\\n",
      "1  331.352397  140.093791  445.258000  278.736400  320.946834  76.329016   \n",
      "2  340.420830  140.420811  446.779600  276.008700  321.614284  74.956876   \n",
      "3  337.478479  138.773703  447.954901  264.340102  319.352410  75.242281   \n",
      "4  334.305237  140.644779  448.059901  273.502300  319.230396  74.377237   \n",
      "5  333.404049  144.263446  447.424101  273.400302  323.729391  75.472787   \n",
      "6  322.009162  141.132288  448.003601  275.289203  325.367045  75.281324   \n",
      "7  324.368623  139.078420  447.951401  286.541201  319.247229  75.540783   \n",
      "8  323.273178  138.074099  448.059901  288.497100  321.900583  74.408892   \n",
      "9  321.338571  132.816746  448.059901  295.677499  320.269265  73.786654   \n",
      "\n",
      "         PFE         SAP         WMT  \n",
      "0  42.853865  132.939397  151.089664  \n",
      "1  43.027936  131.764676  150.022136  \n",
      "2  44.248157  132.778457  149.876960  \n",
      "3  42.263819  133.218028  148.646725  \n",
      "4  42.047207  137.008105  147.803157  \n",
      "5  42.110956  139.327853  147.451981  \n",
      "6  41.860263  134.440845  147.793057  \n",
      "7  41.097815  135.013893  147.626954  \n",
      "8  39.595166  136.279377  147.136432  \n",
      "9  38.183496  136.053577  146.603387  \n",
      "AAPL    0.183039\n",
      "AMD    -2.526098\n",
      "AMZN   -1.114006\n",
      "CCJ     0.238798\n",
      "COST    0.381979\n",
      "GOOG   -2.096753\n",
      "GS     -0.596270\n",
      "JPM    -1.168610\n",
      "LLY     0.043394\n",
      "META   -0.431324\n",
      "MSFT   -0.031225\n",
      "NEE    -0.038009\n",
      "PFE    -1.281757\n",
      "SAP    -0.324932\n",
      "WMT     0.073411\n",
      "Name: mkt, dtype: float64\n",
      "OrderedDict([('AAPL', 0.0908), ('AMD', 0.05), ('AMZN', 0.05), ('CCJ', 0.081), ('COST', 0.09423), ('GOOG', 0.05), ('GS', 0.0509), ('JPM', 0.05), ('LLY', 0.083), ('META', 0.05), ('MSFT', 0.07704), ('NEE', 0.07252), ('PFE', 0.05), ('SAP', 0.06863), ('WMT', 0.08189)])\n"
     ]
    }
   ],
   "source": [
    "future_prices = pd.DataFrame(future_prices)\n",
    "print(future_prices)\n",
    "\n",
    "# Construct covariance matrix of future stock prices\n",
    "# cov_matrix = risk_models.sample_cov(future_prices)\n",
    "S = risk_models.CovarianceShrinkage(future_prices).ledoit_wolf()\n",
    "# plotting.plot_covariance(S, plot_correlation=True)\n",
    "\n",
    "# Use capm to find expected returns on future prices\n",
    "mu = expected_returns.capm_return(future_prices)\n",
    "print(mu)\n",
    "# Do mean variance optimization using efficient frontier\n",
    "rf_ef = EfficientFrontier(mu, S, weight_bounds=(0.05, 0.1))\n",
    "rf_ef.min_volatility()\n",
    "weights = rf_ef.clean_weights()\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 1 features, but MinMaxScaler is expecting 10 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[137], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m scaler \u001b[39m=\u001b[39m MinMaxScaler()\n\u001b[0;32m      5\u001b[0m prices_x_scaled \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mfit_transform(short_window_prices[ticker][\u001b[39m0\u001b[39m])\n\u001b[1;32m----> 6\u001b[0m prices_y_scaled \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39;49mtransform(np\u001b[39m.\u001b[39;49mreshape(short_window_prices[ticker][\u001b[39m1\u001b[39;49m], (\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m)))\n\u001b[0;32m      7\u001b[0m prices_test_scaled \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mtransform(short_window_prices[ticker][\u001b[39m2\u001b[39m])\n\u001b[0;32m      9\u001b[0m \u001b[39m# Create and train the MLPRegressor model\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:508\u001b[0m, in \u001b[0;36mMinMaxScaler.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Scale features of X according to feature_range.\u001b[39;00m\n\u001b[0;32m    495\u001b[0m \n\u001b[0;32m    496\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[39m    Transformed data.\u001b[39;00m\n\u001b[0;32m    505\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    506\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 508\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    509\u001b[0m     X,\n\u001b[0;32m    510\u001b[0m     copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy,\n\u001b[0;32m    511\u001b[0m     dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES,\n\u001b[0;32m    512\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    513\u001b[0m     reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    514\u001b[0m )\n\u001b[0;32m    516\u001b[0m X \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale_\n\u001b[0;32m    517\u001b[0m X \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\base.py:588\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    585\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    587\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m--> 588\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[0;32m    590\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\base.py:389\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 389\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    390\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    391\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    392\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 1 features, but MinMaxScaler is expecting 10 features as input."
     ]
    }
   ],
   "source": [
    "\n",
    "future_prices = {}\n",
    "for ticker in tickers:\n",
    "    # Scale the input data\n",
    "    scaler = MinMaxScaler()\n",
    "    prices_x_reshaped = np.reshape(short_window_prices[ticker][0], (len(short_window_prices[ticker][0]), measurement_days))  # Reshape prices_x\n",
    "    prices_x_scaled = scaler.fit_transform(prices_x_reshaped)\n",
    "    prices_y_scaled = scaler.transform(np.reshape(short_window_prices[ticker][1], (-1, 1)))\n",
    "    prices_test_scaled = scaler.transform(short_window_prices[ticker][2])\n",
    "\n",
    "    # Create and train the MLPRegressor model\n",
    "    model = MLPRegressor(hidden_layer_sizes=(64, 64), activation='relu', solver='adam', random_state=42)\n",
    "    model.fit(prices_x_scaled, prices_y_scaled)\n",
    "\n",
    "    # Predict future prices\n",
    "    future_prices[ticker] = scaler.inverse_transform(model.predict(prices_test_scaled))\n",
    "\n",
    "future_prices = pd.DataFrame(future_prices, index=range(measurement_days, measurement_days + remaining_days))\n",
    "# future_prices = {}\n",
    "\n",
    "# for ticker in tickers:\n",
    "#     price_movements = np.array([1 if stock_data[i+measurement_days] > stock_data[i+measurement_days-1] else 0 for i in range(len(stock_data)-measurement_days)])\n",
    "#     price_movements = price_movements[measurement_days:]\n",
    "\n",
    "#     logreg = LogisticRegression()\n",
    "#     logreg.fit(short_window_prices[ticker][0], price_movements)\n",
    "\n",
    "#     future_price_movements = logreg.predict_proba(short_window_prices[ticker][2])[:, 1]\n",
    "#     future_prices[ticker] = [stock_prices[ticker][-1] * (1 + movement) for movement in future_price_movements]\n",
    "\n",
    "\n",
    "# future_prices = pd.DataFrame(future_prices)\n",
    "# print(future_prices)\n",
    "\n",
    "# Construct covariance matrix of future stock prices\n",
    "# cov_matrix = risk_models.sample_cov(future_prices)\n",
    "S = risk_models.CovarianceShrinkage(future_prices).ledoit_wolf()\n",
    "# plotting.plot_covariance(S, plot_correlation=True)\n",
    "\n",
    "# Use capm to find expected returns on future prices\n",
    "mu = expected_returns.capm_return(future_prices)\n",
    "print(mu)\n",
    "# Do mean variance optimization using efficient frontier\n",
    "logreg_ef = EfficientFrontier(mu, S, weight_bounds=(0.05, 0.1))\n",
    "logreg_ef.min_volatility()\n",
    "weights = logreg_ef.clean_weights()\n",
    "print(weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL    2.000000e-02\n",
      "AMD     2.000000e-02\n",
      "AMZN    2.000000e-02\n",
      "CCJ     1.918831e+07\n",
      "COST    1.569952e+07\n",
      "GOOG    2.000000e-02\n",
      "GS     -1.569952e+07\n",
      "JPM     2.000000e-02\n",
      "LLY     8.721957e+06\n",
      "META    2.000000e-02\n",
      "MSFT    4.535418e+07\n",
      "NEE     2.000000e-02\n",
      "PFE     2.000000e-02\n",
      "SAP    -1.221074e+07\n",
      "WMT     2.616587e+07\n",
      "Name: mkt, dtype: float64\n",
      "OrderedDict([('AAPL', 0.06833), ('AMD', 0.07172), ('AMZN', 0.06833), ('CCJ', 0.05), ('COST', 0.05), ('GOOG', 0.06833), ('GS', 0.1), ('JPM', 0.06833), ('LLY', 0.05), ('META', 0.06833), ('MSFT', 0.05), ('NEE', 0.06833), ('PFE', 0.06833), ('SAP', 0.1), ('WMT', 0.05)])\n"
     ]
    }
   ],
   "source": [
    "future_prices = {}\n",
    "\n",
    "for ticker in tickers:\n",
    "    svm = SVC(kernel='poly')\n",
    "    svm.fit(short_window_prices[ticker][0], price_movements)\n",
    "    \n",
    "    future_price_movements = svm.predict(short_window_prices[ticker][2])\n",
    "    future_prices[ticker] = [stock_prices[ticker][-1] * (1 + movement) for movement in future_price_movements]\n",
    "\n",
    "future_prices = pd.DataFrame(future_prices)\n",
    "# Construct covariance matrix of future stock prices\n",
    "# cov_matrix = risk_models.sample_cov(future_prices)\n",
    "S = risk_models.CovarianceShrinkage(future_prices).ledoit_wolf()\n",
    "# plotting.plot_covariance(S, plot_correlation=True)\n",
    "\n",
    "# Use capm to find expected returns on future prices\n",
    "mu = expected_returns.capm_return(future_prices)\n",
    "print(mu)\n",
    "# Do mean variance optimization using efficient frontier\n",
    "svm_ef = EfficientFrontier(mu, S, weight_bounds=(0.05, 0.1))\n",
    "svm_ef.min_volatility()\n",
    "weights = svm_ef.clean_weights()\n",
    "print(weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected annual return: -40.0%\n",
      "Annual volatility: 7.7%\n",
      "Sharpe Ratio: -5.44\n",
      "\n",
      "\n",
      "Expected annual return: 6338987828062.7%\n",
      "Annual volatility: 249.2%\n",
      "Sharpe Ratio: 25434617140.36\n",
      "\n",
      "\n",
      "Expected annual return: 296546535.1%\n",
      "Annual volatility: 113.9%\n",
      "Sharpe Ratio: 2604464.20\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_ef.portfolio_performance(verbose=True)\n",
    "print(\"\\n\")\n",
    "logreg_ef.portfolio_performance(verbose=True)\n",
    "print(\"\\n\")\n",
    "svm_ef.portfolio_performance(verbose=True)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean-Variance Optimization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
